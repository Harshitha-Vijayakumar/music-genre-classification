{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries to be included\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/kaggle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaggle API command\n",
    "!kaggle datasets download -d andradaolteanu/gtzan-dataset-music-genre-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unzipping the file that was downloaded\n",
    "import zipfile\n",
    "\n",
    "file_path = '/content/gtzan-dataset-music-genre-classification.zip'\n",
    "\n",
    "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing the images into 180x180 size and converting them to tensor\n",
    "transform = transforms.Compose([transforms.Resize((180, 180)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/content/Data/images_original'\n",
    "dataset = datasets.ImageFolder(root=data_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into 70, 20 and 10 for training, validation and testing\n",
    "train, val = int(len(dataset)*0.7), int(len(dataset)*0.2)\n",
    "test = int(len(dataset) - train - val)\n",
    "train_data, val_data, test_data = random_split(dataset, [train, val, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(train_loader)\n",
    "samples, labels = next(examples)\n",
    "samples.shape, labels.shape #To check the input tensor size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(6):\n",
    "  plt.subplot(2, 3, i+1)\n",
    "  plt.imshow(samples[i][0], cmap='gray')\n",
    "plt.show() #Viewing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "def train_model(epochs, train_loader, model, loss_function, optimizer):\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for imgs, labels in train_loader:\n",
    "      imgs = imgs.cuda()\n",
    "      labels = labels.cuda()\n",
    "\n",
    "      #forward\n",
    "      output = model(imgs)\n",
    "      loss = loss_fn(output, labels)\n",
    "\n",
    "      #backward\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    print(f'epoch{epoch+1}/{epochs}, loss = {loss.item():.4f}')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of the validation set\n",
    "def eval1(model):\n",
    "  correct = 0\n",
    "  total = 0.0\n",
    "  with torch.no_grad():\n",
    "      for images, labels in val_loader:\n",
    "          images = images.view(images.size(0), -1)  # Flatten the images\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  val_accuracy = correct / total * 100\n",
    "  return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of the testing set\n",
    "def eval2(model):\n",
    "  correct = 0\n",
    "  total = 0.0\n",
    "  with torch.no_grad():\n",
    "      for images, labels in test_loader:\n",
    "          images = images.view(images.size(0), -1)  # Flatten the images\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  test_accuracy = correct / total * 100\n",
    "  return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolutional Neural Network with Batch Normalization Layer\n",
    "\n",
    "class Net3(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv_layer1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.conv_layer2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3)\n",
    "    self.relu_layer = nn.ReLU()\n",
    "    self.max_pool_layer1 = nn.MaxPool2d(kernel_size = (2,2))\n",
    "\n",
    "    self.conv_layer3 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3)\n",
    "    self.relu_layer = nn.ReLU()\n",
    "    self.conv_layer4 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
    "    self.relu_layer = nn.ReLU()\n",
    "    self.max_pool_layer2 = nn.MaxPool2d(kernel_size = (2,2))\n",
    "\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.fc_layer1 = nn.Linear(in_features = 64 * 42 * 42, out_features = 256)\n",
    "    self.fc_layer2 = nn.Linear(in_features = 256, out_features = 10)\n",
    "\n",
    "    #Batch Normalization Layer\n",
    "    self.batch_norm1 = torch.nn.BatchNorm2d(num_features = 32)\n",
    "    self.batch_norm2 = torch.nn.BatchNorm2d(num_features = 32)\n",
    "    self.batch_norm3 = torch.nn.BatchNorm2d(num_features = 64)\n",
    "    self.batch_norm4 = torch.nn.BatchNorm2d(num_features = 64)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    x = self.conv_layer1(x)\n",
    "    x = self.batch_norm1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv_layer2(x)\n",
    "    x = self.batch_norm2(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.max_pool_layer1(x)\n",
    "\n",
    "    x = self.conv_layer3(x)\n",
    "    x = self.batch_norm3(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.conv_layer4(x)\n",
    "    x = self.batch_norm4(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.max_pool_layer1(x)\n",
    "\n",
    "    x = self.flatten(x)\n",
    "\n",
    "    x = self.fc_layer1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc_layer2(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Net3()\n",
    "model3 = model3.cuda()\n",
    "loss_fn = nn.CrossEntropyLoss() #Loss function - Cross entropy\n",
    "optimizer = optim.Adam(model3.parameters()) #Optimizer - Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 50 epochs\n",
    "model3 = train_model(50, train_loader, model3, loss_fn, optimizer)\n",
    "val_accuracy = eval1(model3)\n",
    "print(f'Accuracy on Validation set: {val_accuracy}')\n",
    "test_accuracy = eval2(model3)\n",
    "print(f'Accuracy on Test set: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For 100 epochs\n",
    "model3 = train_model(100, train_loader, model3, loss_fn, optimizer)\n",
    "val_accuracy = eval1(model3)\n",
    "print(f'Accuracy on Validation set: {val_accuracy}')\n",
    "test_accuracy = eval2(model3)\n",
    "print(f'Accuracy on Test set: {test_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
